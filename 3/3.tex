\section{Принцип плагина}

Принцип плагина представляет собой простой метод оценки параметров по выборкам. Плагин оценка параметра $\theta = t (F)$ определяется как 
\begin{equation}
    \hat\theta=t(\hat F).
\end{equation}
Другими словами, мы оцениваем функцию $\theta = t (F)$ распределения вероятностей $F$ той же функцией эмпирического распределения $\hat F$, $\hat\theta = t (\hat F)$. (Статистические данные, подобные (4.13), которые используются для оценки параметров, иногда называют суммарной статистикой, а также оценками и оценщиками.) 

Мы уже использовали принцип плагина при оценке $f_k$ через $\hat f_k$ и при оценке $corr (y, z)$ с помощью $\widehat{corr} (y, z)$. Чтобы убедиться в этом, обратите внимание, что наша совокупность $F$ юридических школ может быть записана как $F = (f_1, f_2,\cdots ,f_82)$, где каждое $f_j$, вероятность j-го юридической школы, имеет значение 1/82. Это распределение вероятностей на $\mathbf{X}$, 82 парах юридических школ. Коэффициент корреляции генеральной совокупности можно записать как 
\begin{equation}
    corr(y,z)=\frac{\sum_{j=1}^{82}f_j(Y_j-\mu_y)(Z_j-\mu_z)}{[\sum_{j=1}^{82}f_j(Y_j-\mu_y)^2\sum_{j=1}^{82}f_j(Z_j-\mu_z)^2]^\frac{1}{2}},
\end{equation}
где
\begin{equation}
    \mu_y=\sum_{j=1}^{82}f_jY_j,\qquad\mu_z=\sum_{j=1}^{82}f_jZ_j.
\end{equation}
Установка каждого $f_j = 1/82$ дает выражение (4.4). Теперь для нашей выборки $(x_1, x_2,\cdots, x_15)$ выборочная частота $\hat f_j$ -- это доля точек выборки, равная $X_j$:
\begin{equation}
    \hat f_j=\#\{x_i=X_j\}/15, j=1,2,\ldots,82.
\end{equation}
Для выборки из Таблицы 3.1 $\hat f_1 = 0, \hat f_2 = 0, \hat f_3 = 0, \hat f_4 = 1/15$ и т.д. Теперь подставив эти значения $\hat f_j$ в выражения (4.15) и (4.14), получим $\hat\mu_y$, $\hat\mu_z$ и $\widehat{corr} (y, z)$ соответственно. То есть $\hat\mu_y$, $\hat\mu_z$ и $\widehat{corr} (y, z)$ -- это плагин оценки $\mu_y$, $\mu_z$ и $corr (y, z)$. 

В общем, плагин оценка математического ожидания $\theta = E_F (x)$ равна 
\begin{equation}
    \hat\theta = E_{\hat F} (x)=\frac{1}{n}\sum_{i=1}^nx_i=\bar x.
\end{equation}

Насколько хорош принцип плагина? Обычно, если единственная доступная информация о $F$ исходит из выборки $\mathbf{x}$, то $\hat\theta = t (\hat F)$ не может быть улучшена как оценка $\theta = t (F)$, по крайней мере, не в обычном асимптотическом ($n\rightarrow\infty$) смысле статистической теории. Например, если $\hat f_k$ -- плагин оценка частоты $\#\{x_i = k\} / n$, то 
\begin{equation}
    \hat f_k\sim Bi(n,f_k)/n.
\end{equation}
В этом случае оценка $\hat f_k$ является несмещенной для $f_k$, $E(\hat f_k) = f_k$, с дисперсией $f_k (1-f_k) / n$. Это наименьшая возможная дисперсия для несмещенной оценки $f_k$. 

Мы будем использовать бутстреп для изучения смещения и стандартной ошибки плагин оценки $\hat\theta = t (\hat F)$. Достоинство бутстрепа состоит в том, что он автоматически создает смещения и стандартные ошибки, независимо от того, насколько сложным может быть функциональное сопоставление $\theta = t (F)$. Мы увидим, что сам бутстреп является применением плагин принципа. 

Принцип плагина менее эффективен в ситуациях, когда имеется информация о $F$, отличная от той, которая предоставлена выборкой $\mathbf{x}$. Мы можем знать или предполагать, что $F$ является членом параметрического семейства, например семейства многомерных нормальных распределений. Или мы можем оказаться в ситуации регрессии, когда у нас есть набор случайных выборок $\mathbf{x} (z)$ в зависимости от переменной-предиктора $z$. Тогда, даже если нас интересует только $F_{z_0}$, функция распределения для некоторого конкретного значения $z_o$ из $z$, может быть информация о $F_{z_o}$ в других выборках $\mathbf{x} (z)$, особенно тех, для которых $z$ близок к $z_0$.

Принцип плагина и бутстреп могут быть адаптированы к параметрическим семействам и регрессионным моделям. В следующих нескольких главах мы предполагаем, что находимся в ситуации, когда у нас есть только одна случайная выборка $\mathbf{x}$ из полностью неизвестного распределения $F$. Это называется непараметрической задачей с одной выборкой.