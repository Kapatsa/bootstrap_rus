
\section{$\tx{C}_\tx{p}$ и другие оценки ошибки предсказания}
Есть и другие способы оценки ошибки предсказания, и все они основаны на остаточной стандартной ошибке RSE. Последняя часть этой главы описывает бутстреп подход. Простая аналитическая мера --- скорректированная остаточная стандартная ошибка:
\begin{equation}
\frac{\tx{RSE}}{(n - 2p)},
\end{equation}
где $p$ обозначает количество регрессоров в модели. 
Эта корректировка $\tx{RSE} / n$ позволит учесть подгонку, чем больше $p$ тем выше степень коррекции. Обратите внимание, что $\tx{RSE} / (n-2p)$ является более серьезной коррекций RSE, чем несмещенная оценка дисперсии $\tx{RSE} / (n-p)$.

Другая оценка (одна из форм) --- это $\tx{C}_\tx{p}$ статистика:
\begin{equation}
\tx{C}_\tx{p} = \frac{\tx{RSE}}{n} + \frac{2p\what{\sigma}^{2}}{n}.
\end{equation}
Здесь $\what{\sigma}^{2}$ --- оценка остаточной дисперсии, разумным было бы положить ее равной $\tx{RSE} / (n - p)$. (При вычислении $\tx{C}_\tx{p}$ статистики для ряда моделей $\what{\sigma}^{2}$ вычисляется один раз на основе $\tx{RSE} / (n - p)$ для некоторой фиксированной большой модели). 
Данная татистика является частным случаем информационного критерия Акаике (AIC) для общих моделей. Это позволяет скорректировать $\tx{RSE} / n$ так, чтобы получить приблизительно несмещенную оценку для ошибки предсказания: $\tx{E}(\tx{C}_\tx{p}) \approx \tx{PE}$.

Неявно эти поправки учитывают еще и тот факт, что одни и те же данные используются как для построения модели, таки и для ее оценки с помощью остаточной стандартной ошибки. Заметим что <<$p$>> в знаменателе и второй член в $\tx{C}_\tx{p}$ --- это штрафы, учитывающие степень подгонки. Простой аргумент показывает, что скорректированная остаточная стандартная ошибка и $\tx{C}_\tx{p}$ статистика эквивалентны первому порядку аппроксимации.

Также $\tx{C}_\tx{p}$ статистика подобна критерию Шварца или BIC (байесовский информационный критерий).
\begin{equation}
\tx{BIC} = \frac{\tx{RSE}}{n} +\frac{ \log n \cdot p \what{\sigma}^{2}}{n}.
\end{equation}
Если сравнить $\tx{C}_\tx{p}$ и BIC, то можно заметить, что в последнем на месте <<2>> стоит $\log n$, а следовательно, назначается больший штраф, чем в $\tx{C}_\tx{p}$, так как, $n > e^{2}$. Таким образом, при сравнении моделей с помощью BIC будут выбираться модели с меньшим числом регресоров, чем при сравнении с помощью $\tx{C}_\tx{p}$. Можно показать, что BIC является состоятельным критерием в том смысле, что он выбирает правильную модель при $n \rightarrow \infty $. Это не относится к скорректированной RSE или $\tx{C}_\tx{p}$.

В примере с гормоном $\tx{RSE} = 59.27$, $\what{\sigma}^{2} = 2.58$ и $p = 4$ следовательно, $\tx{RSE} / (n - 2p) = 3.12$, $\tx{C}_\tx{p} = 2.96$, $\tx{BIC} = 3.45$, по сравнению со значения CV, равным 3.09.

Зачем использовать кросс-валидацию, когда есть более простые альтернативы? Основная причина заключается в том, что для задач построения модели методом более сложным чем методот наименьших квадратов, количество параметров <<$p$>> не является известным. В отличие от кросс-валидации, скорректированная RSE, $\tx{C}_\tx{p}$ статистика и BIC требуют знания $p$. Как и бутстреп, в простых задачах кросс-валидация стремиться давать ответы, аналогичные тем что дают стандартные методы, и ее приемущество заключается в ее применимости к более сложным ситуациям. Ниже приведен пример деревьев классификации.

Второе преимущество кросс-валидации --- это ее надежность. $\tx{C}_\tx{p}$ статистика и BIC требуют приблизительно правильной модели для получения оценки $\what{\sigma}^{2}$. Кросс-валидации  не требует этого и будет хорошо работать, даже если оцениваемые модели далеки от правильности.

Теперь, ответим на второй вопрос, который обсуждался выше, касательно модели с одинаковыми угловыми коэффициентами, но с отдельнми линиями регрессии для каждой партии и простой моделью, которая определяет одну общую линию регрессии для всех партий сразу. Таким же образом, как описано выше, мы можем вычислить сумму квадратов с помощью кросс-валидации для модели с одной линией регрессии. Это значение равно $5.89$, что немного больше, чем  значение равное $3.27$, полученное для случая, когда для каждой партии допускается свое значение свободного члена. Это неудивительно, учитывая статистически значимые различия между свободными членами в таблице 9.3. Но кросс-валидация полезна, поскольку она дает количественную оценку цены, которую иследователь заплатил бы, если бы он не внес поправку на номер партии устройства.