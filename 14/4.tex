\section{Метод $\abc$}
Главный недостаток метода $\bca$ заключается в необходимости проведения большого числа итераций. В главе 19 показано, что для удовлетворительного уменьшения ошибки Монте-Карло требуется не менее $B = 1000$ репликаций. Метод $\abc$ (\textit{approximate bootstrap confidence}) представляет из себя метод, который оценивает границы интервалов аналитически, без использования репликаций Монте-Карло. Данная аппроксимация обычно оказывается достаточно неплохой, что видно из результатов в таблице 14.2. (Разница между граничными точками $\bca$ и $\abc$ объясняется вариативностью Монте-Карло при вычислении $\bca$ интервала. Увеличение $B$ до $10000$ параметрических репликаций дает $\bca$ интервал $(118.4,303.8)$, практически совпадающий с $\abc$ интервалом.)

Метод $\abc$ описан в главе 22. Его работа заключается в аппроксимации результатов бутстреп моделирования используя разложения Тейлора.  Для этого необходимо, чтобы оцениваемая статистика $\what \theta = s(\mbf x)$ была гладкой по $\mbf x$. Пример негладкой статистики --- выборочная медиана. Для большинства часто встречающихся статистик метод $\abc$ оказывается весьма удовлетворительным. (Контрпример приведен в разделе 14.5.) Построенные по $\abc$ интервалы --- как и граничные точки по методу $\bca$  --- сохраняют отображения и имеют второй порядок точности. Для построения оценок по методу $\abc$ в таблице 14.2 потребовалось всего $3\%$  вычислительных затрат, необходимых для построения $\bca$ интервала.

Непараметрические границы по методу $\abc$ в таблице 14.2 были получены из алгоритма \texttt{abcnon}, приведенном в приложении. Для использования этого алгоритма статистика $\what \theta$ должна быть представлена в специальной форме (\textit{resampling form}). Как будет показано в главе 20, эта форма важна для развития теории бутстреп методов. Форма была определена в разделе 10.4. Фиксировав исходную выборку $\mbf x = (\xes{n}),$ запишем бутстреп значение $\what \theta^* = s(\mbf x^*)$ как функцию вектора повторной выборки $\mbf P^*$, то есть
\begin{equation}
  \what \theta^* = T(\mbf P^*).
\end{equation}
Вектор $\mbf P^* = (P_1^*, P_2^*, \ldots, P_n^*)$ состоит из долей
\begin{equation}
  P_i^* = N_i^*/n = \frac{\#\{x_j^*> x_i\}}{n} \qquad (i = \ies{n}).
\end{equation}

Статистика $\what \theta^* = \sum_{i = 1}^{n} (A_i^* - \bar A^*)^2/n$, (14.3), может быть представлена в виде (14.20) следующим образом
\begin{equation}
  \what \theta ^* = \sum_{i = 1}^n P_i^* (A_i - \bar A^*)^2, \tx{ где} \quad \bar A^* = \summ{i =1}{n} P_i^* A_i. 
\end{equation}
Функция $T(\mbf P^*)$ из (14.20) есть необходимая форма статистики, которая используется в алгоритме $\abc$. Напомним,  определен и следующий вектор повторной выборки
\begin{equation}
  \mbf P^0 = (1/n,1/n,\ldots,1/n)
\end{equation}
для которого выполняется $T(\mbf P^0) = \what \theta$, исходное значение статистики. Алгоритм \texttt{abcnon} требует, чтобы  $T(\mbf P^*)$ была гладкой для $\mbf P^*$ в окрестности $\mbf P^0$. Это происходит естественным образом, как в (14.22), для статистик по методу подстановки $\what \theta = t(\what F)$.

Типичный вызов функции \texttt{abcnon} имеет вид
\begin{equation}
  \texttt{abcnon}(\texttt x, \texttt{tt}), 
\end{equation}
где \texttt x --- данные, \texttt{tt} --- статистика $\what \theta ^*$ в специальной форме. Больше информации --- в приложении.

Подводя итоги, $\abc$ интервалы сохраняют отображения, имеют второй порядок точности, а также служат хорошим приближением $\bca$ интервалов для крупного класса гладких статистик $\what \theta^* = s(\mbf x^*)$. Для реализации \texttt{abcnon} алгоритма $\abc$ требуется, чтобы статистика была приведена в специальной форме $\what \theta^* = T(\mbf P^*)$.  В то же время, удобная и простая реализация, а также серьезные вычислительные преимущества указывают на пригодность данного подхода.
