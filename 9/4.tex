\section{Применение бутстрепа}

Пока ни один из расчетов не требует бутстрепа. Однако полезно выполнить бутстреп-анализ для модели линейной регрессии. Оказывается, оценки стандартной ошибки бустрепа такие же, как $\widehat{\text{se}}(\hat{\beta}_j)$, (9.20). Убедившись, что бутстреп дает разумные ответы в случае, который мы можем проанализировать математически, мы можем продолжить применять бутстреп к более общим моделям регрессии, которые не имеют математического решения: где функция регрессии нелинейна по параметрам $\bm{\beta}$, и где мы используем методы подбора, отличные от метода наименьших квадратов.

Вероятностная модель $P \to \textbf{x}$ для линейной регрессии, как описано в (9.4), (9.5), состоит из двух компонентов:
\begin{equation}
	P = (\bm{\beta}, F),
\end{equation}
где $\bm{\beta}$ --- вектор параметров коэффициентов регрессии, а $F$ --- распределение вероятностей ошибок. Общий алгоритм бустрепа на рис. 8.3 требует, чтобы мы оценили $P$. У нас уже есть доступная $\hat{\bm{\beta}}$ --- оценка методом наименьших квадратов для $\bm{\beta}$. Как мы можем оценить $F$? Если предположить, что $\bm{\beta}$ известно, мы могли бы вычислить ошибки $\varepsilon_i = y_i - \textbf{c}_i \bm{\beta}$ для $i = 1,2, \ldots, n$ и оценить $F$ по их эмпирическому распределению. Мы не знаем $\bm{\beta}$, но можем использовать $\hat{\bm{\beta}}$ для вычисления аппроксимаций ошибок
\begin{equation}
	\hat{\varepsilon}_i = y_i - \textbf{c}_i \hat{\bm{\beta}}, \text{  для  } i = 1,2, \ldots, n.
\end{equation}
($\hat{\varepsilon}_i$ также называют \textit{остатками}.) Очевидная оценка $F$ --- это эмпирическое распределение $\hat{\varepsilon}_i$,
\begin{equation}
	\hat{F}: \text{ вероятность } 1/n \text{ для } \hat{\varepsilon}_i \text{ при } i = 1,2, \ldots, n.
\end{equation}
Обычно $\hat{F}$ будет иметь математическое ожидание $0$, как требуется в (9.5).

Имея $\hat{P} = (\hat{\bm{\beta}}, \hat{F})$, мы знаем, как рассчитать бутстреп наборы данных для модели линейной регрессии, в этом случае вероятностный механизм $\hat{P} \to \textbf{x}^*$ должен означать то же самое, что и вероятностный механизм $P \to \textbf{x}$, дающий фактический набор данных $\textbf{x}$, см. (9.4), (9.5). Чтобы сгенерировать $\textbf{x}^*$, мы сначала выбираем случайную выборку бустреп ошибок
\begin{equation}
	\hat{F} \to (\varepsilon_1^*, \varepsilon_2^*, \ldots, \varepsilon_n^*) = \bm{\varepsilon}^*.
\end{equation}
Каждый $\varepsilon_i^*$ равен любому из $n$ значений $\hat{\varepsilon}_j$ с вероятностью $1 / n$. Затем бустреп ответы $y_i^*$ генерируются согласно (9.4),
\begin{equation}
	y_i^* = \textbf{c}_i \hat{\bm{\beta}} + \varepsilon_i^* \text{  для  } i = 1,2,\ldots,n.
\end{equation}
Читатель должен убедиться, что формулы (9.24), (9.25), (9.26) есть то же самое, что (9.4), (9.5), за исключением того, что $\hat{P} = (\hat{\bm{\beta}}, \hat{F})$ заменяет $P = (\bm{\beta}, F)$. Обратите внимание, что $\hat{\bm{\beta}}$ --- фиксированная величина в (9.26), имеющая одинаковые значения для всех $i$.

Бутстреп набор данных $\textbf{x}^*$ представляет из себя $(\textbf{x}_1^*, \textbf{x}_2^*, \ldots, \textbf{x}_n^*)$, где $\textbf{x}_i^* = (\textbf{c}_i, y_i^*)$. Может показаться странным, что векторы признаков $\textbf{c}_i$ для бутстреп данных такие же, как и для фактических данных. Это происходит потому, что мы рассматриваем $\textbf{c}_i$ как фиксированные величины, а не как случайные. (Во всех наших примерах размер выборки $n$ трактовался одинаково.) Этот момент дополнительно обсуждается ниже.

Бустреп оценка $\hat{\bm{\beta}}^*$ методом наименьших квадратов является минимизатором квадратичной остаточной ошибки для бустреп данных,
\begin{equation}
	\sum\limits_{i=1}^{n}(y_i^* - \textbf{c}_i \hat{\bm{\beta}}^*)^2 = \min_{\textbf{b}} (y_i^* - \textbf{c}_i \textbf{b})^2.
\end{equation}
Нормальные уравнения (9.10), примененные к бутстреп данным, дают
\begin{equation}
	\hat{\bm{\beta}}^* = (\textbf{C}^\text{T} \textbf{C})^{-1} \textbf{C}^\text{T} \textbf{y}^*.
\end{equation}

В этом случае нам не нужны симуляции Монте--Карло, чтобы вычислить бутстреп стандартные ошибки для компонентов $\hat{\bm{\beta}}^*$. Несложный расчет дает выражение в явной форме для $\text{se}_{\hat{F}} (\hat{\bm{\beta}}_j^*) = \widehat{\text{se}}_{\infty} (\hat{\beta}_j)$, идеальной оценки бутстреп стандартной ошибки:
\begin{align}
	\text{var}(\hat{\bm{\beta}}^*) & = (\textbf{C}^\text{T} \textbf{C})^{-1} \textbf{C}^\text{T} \text{var}(\textbf{y}^*) \textbf{C}(\textbf{C}^\text{T} \textbf{C})^{-1} = \notag \\
	& = \hat{\sigma}_F^2 (\textbf{C}^\text{T} \textbf{C})^{-1},
\end{align}
поскольку $\text{var}(\textbf{y}^*) = \hat{\sigma}^2_F \textbf{I}$, где $\textbf{I}$ --- единичная матрица. Следовательно
\begin{equation}
	\widehat{\text{se}}_{\infty}(\hat{\beta}_j) = \hat{\sigma}_F \sqrt{G^{jj}}.
\end{equation}
Другими словами, бутстреп оценка стандартной ошибки для $\hat{\beta}_j$ такая же, как и обычная оценка $\widehat{\text{se}}(\hat{\beta}_j)$, (9.20).